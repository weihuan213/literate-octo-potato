{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib\n",
    "\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file D:\\研究生\\mne\\mne_data\\out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_meg.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading events from D:\\研究生\\mne\\mne_data\\out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_events.tsv.\n",
      "Reading channel info from D:\\研究生\\mne\\mne_data\\out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_channels.tsv.\n",
      "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-51eabae648ce>:8: RuntimeWarning: The unit for channel(s) STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, STI 015, STI 016 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 19821 samples (33.001 sec)\n",
      "\n",
      "Used Annotations descriptions: ['Auditory/Left', 'Auditory/Right', 'Button', 'Smiley', 'Visual/Right', 'Visual/left']\n"
     ]
    }
   ],
   "source": [
    "bids_root = pathlib.Path('D:/研究生/mne/mne_data/out_data/sample_BIDS/')\n",
    "bids_path = mne_bids.BIDSPath(subject=\"01\", \n",
    "                             session=\"01\", \n",
    "                             task=\"audiovisual\",\n",
    "                             run=\"01\",\n",
    "                             datatype='meg',\n",
    "                             root=bids_root)\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.load_data()\n",
    "raw.filter(l_freq=0.1, h_freq=40)\n",
    "events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Auditory/Left': 1,\n",
       " 'Auditory/Right': 2,\n",
       " 'Button': 3,\n",
       " 'Smiley': 4,\n",
       " 'Visual/Right': 5,\n",
       " 'Visual/left': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定epoch、event的起点、终点，单位是s\n",
    "### 对于baseline的解释：当使用baseline矫正的时候，将一个时间间隔看作是“baseline”。\n",
    "### 如果值为None，不会使用baseline矫正，我的理解是在tmin和tmax上面的一个修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "320 matching events found\n",
      "Setting baseline interval to [-0.2996928197375818, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "3 projection items activated\n",
      "Loading data for 320 events and 481 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>Auditory/Left: 72<br>Auditory/Right: 73<br>Button: 16<br>Smiley: 15<br>Visual/Right: 71<br>Visual/left: 73<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.300 – 0.499 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.300 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  320 events (all good), -0.299693 - 0.499488 sec, baseline -0.299693 – 0 sec, ~444.8 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Auditory/Right': 73\n",
       " 'Button': 16\n",
       " 'Smiley': 15\n",
       " 'Visual/Right': 71\n",
       " 'Visual/left': 73>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmin = -0.3\n",
    "tmax = 0.5\n",
    "baseline = (None, 0)\n",
    "\n",
    "epochs = mne.Epochs(raw, \n",
    "                   events=events,\n",
    "                   event_id=event_id,\n",
    "                   tmin=tmin,\n",
    "                   tmax=tmax, \n",
    "                   baseline=baseline,\n",
    "                   preload=True)\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x986 with 4 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.plot(events=events, event_id=event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Epochs |  320 events (all good), -0.299693 - 0.499488 sec, baseline -0.299693 – 0 sec, ~444.8 MB, data loaded,\n",
      " 'Auditory/Left': 72\n",
      " 'Auditory/Right': 73\n",
      " 'Button': 16\n",
      " 'Smiley': 15\n",
      " 'Visual/Right': 71\n",
      " 'Visual/left': 73>\n"
     ]
    }
   ],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于实验情况挑选epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>Auditory/Left: 72<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.300 – 0.499 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.300 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  72 events (all good), -0.299693 - 0.499488 sec, baseline -0.299693 – 0 sec, ~102.6 MB, data loaded,\n",
       " 'Auditory/Left': 72>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[\"Auditory/Left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        <td>Auditory/Left: 72<br>Auditory/Right: 73<br></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.300 – 0.499 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.300 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Epochs |  145 events (all good), -0.299693 - 0.499488 sec, baseline -0.299693 – 0 sec, ~203.4 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Auditory/Right': 73>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[\"Auditory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "Dropped 0 epochs: \n",
      "Channels marked as bad: ['MEG 2443', 'EEG 053']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1280x960 with 3 Axes>,\n",
       " <Figure size 1280x960 with 3 Axes>,\n",
       " <Figure size 1280x960 with 3 Axes>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs[\"Visual\"].plot_image()\n",
    "# 这个图可以得到epoch及它的GFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "320 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1280x960 with 3 Axes>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.copy().pick_types(meg=False, eeg=True).plot_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "   <b>保存数据</b>\n",
    "   <ul>\n",
    "        <li>condition为right时，包含了所有右边的事件，听觉的、视觉的</li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "epochs.save(pathlib.Path('D:\\研究生\\mne\\mne_data\\out_data') / 'epoch_epo.fif', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_auditory = epochs['Auditory'].average()\n",
    "evoked_visual = epochs['Visual'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1920x918 with 6 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEFigure size 1500x440 with 5 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory.plot_topomap(ch_type='mag', times=[0.05, 0.10, 0.15, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projections have already been applied. Setting proj attribute to True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x840 with 7 Axes>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joint image 上面两种图的结合\n",
    "evoked_auditory.plot_joint(picks='mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1920x918 with 1 Axes>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_compare_evokeds([evoked_auditory, evoked_visual], picks='mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "   <b>比较图</b>\n",
    "   <ul>\n",
    "       <li>通道选择EEG信号，比较选择左边和右边视觉的刺激</li>\n",
    "   </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_visual_left = epochs['Visual/left'].average()\n",
    "evoked_visual_right = epochs['Visual/Right'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 1920x918 with 1 Axes>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_compare_evokeds([evoked_visual_left, evoked_visual_right], picks='mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | 'Visual/left' (average, N=73), -0.29969 – 0.49949 sec, baseline -0.299693 – 0 sec, 366 ch, ~4.6 MB>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_visual_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存evoke数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.write_evokeds(fname=pathlib.Path('D:\\研究生\\mne\\mne_data\\out_data') / 'evokeds_ave.fif', \n",
    "                 evoked=[evoked_auditory, evoked_visual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取evoke数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\研究生\\mne\\mne_data\\out_data\\evokeds_ave.fif ...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "    Found the data of interest:\n",
      "        t =    -299.69 ...     499.49 ms (0.50 × Auditory/Left + 0.50 × Auditory/Right)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 145 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.299693, 0] sec)\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "    Found the data of interest:\n",
      "        t =    -299.69 ...     499.49 ms (0.49 × Visual/Right + 0.51 × Visual/left)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 144 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.299693, 0] sec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Evoked | '0.50 × Auditory/Left + 0.50 × Auditory/Right' (average, N=145), -0.29969 – 0.49949 sec, baseline -0.299693 – 0 sec, 366 ch, ~4.6 MB>,\n",
       " <Evoked | '0.49 × Visual/Right + 0.51 × Visual/left' (average, N=144), -0.29969 – 0.49949 sec, baseline -0.299693 – 0 sec, 366 ch, ~4.6 MB>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evokeds = mne.read_evokeds(fname=pathlib.Path('D:\\研究生\\mne\\mne_data\\out_data') / 'evokeds_ave.fif')\n",
    "evokeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '0.50 × Auditory/Left + 0.50 × Auditory/Right' (average, N=145), -0.29969 – 0.49949 sec, baseline -0.299693 – 0 sec, 366 ch, ~4.6 MB>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evokeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\研究生\\mne\\mne_data\\out_data\\evokeds_ave.fif ...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "    Found the data of interest:\n",
      "        t =    -299.69 ...     499.49 ms (0.50 × Auditory/Left + 0.50 × Auditory/Right)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 145 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Loaded Evoked data is baseline-corrected (baseline: [-0.299693, 0] sec)\n"
     ]
    }
   ],
   "source": [
    "evokeds = mne.read_evokeds(fname=pathlib.Path('D:\\研究生\\mne\\mne_data\\out_data') / 'evokeds_ave.fif',\n",
    "                          condition='0.50 × Auditory/Left + 0.50 × Auditory/Right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
